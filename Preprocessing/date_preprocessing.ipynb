{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Date Preprocessing\n",
    "\n",
    "This preprocessing file should be utilized to format the data to a format that can be joined by date.\n",
    "- The date column should be named \"date\"\n",
    "- The date column should have the format in \"yyyy-mm\"\n",
    "\n",
    "### Convention\n",
    "- We keep this separated from the final pre-processed files. \n",
    "- We save the date preprocessed files as a csv in the data folder so we don't have to call Redshift (too expensive)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Import Files"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import seaborn as sns\n",
    "from matplotlib import pyplot as plt\n",
    "from pathlib import Path\n",
    "import functools as ft\n",
    "\n",
    "from datetime import datetime\n",
    "\n",
    "import redshift_connector"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Settings"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# path to where we store our preprocessed data\n",
    "data_file_path = Path(\"../data\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Redshift Connection"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "conn = redshift_connector.connect(\n",
    "    host='cspc-workgroup.783764604578.us-west-2.redshift-serverless.amazonaws.com',\n",
    "    database='cspc5071-dsa',\n",
    "    port=5439,\n",
    "    user='python_user',\n",
    "    password='Database123!' # Not best practice but who cares :))\n",
    " )\n",
    "cursor = conn.cursor()\n",
    "\n",
    "# Query to get the list of tables in the specified schema\n",
    "query = f\"\"\"\n",
    "SELECT table_name\n",
    "FROM information_schema.tables\n",
    "WHERE table_schema = 'public'\n",
    "AND table_type = 'BASE TABLE';\n",
    "\"\"\"\n",
    "\n",
    "cursor.execute(query)\n",
    "tables = cursor.fetchall()\n",
    "\n",
    "print(f\"Tables in schema public:\")\n",
    "for table in tables:\n",
    "    print(table[0]) # These are all the data we have in AWS redshift."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Function to query to redshift: Returns a dataframe \n",
    "def querying_to_redshift(query, cursor):\n",
    "    cursor.execute(query)\n",
    "    df : pd.DataFrame = cursor.fetch_dataframe()\n",
    "\n",
    "    return df"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Date Preprocessing for Natural Disasters"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def expand_date_range(row):\n",
    "    date_range = pd.date_range(row[\"start_date\"], row[\"end_date\"], freq=\"MS\").strftime(\"%Y-%m\")\n",
    "    num_months = len(date_range)\n",
    "\n",
    "    return pd.DataFrame({\n",
    "        \"name\": row[\"name\"],\n",
    "        \"disaster_type\": row[\"disaster_type\"],\n",
    "        \"date\": date_range,\n",
    "        \"cpi_adjusted_cost\": row[\"cpi_adjsuted_cost\"] / num_months,\n",
    "        \"unadjusted_cost\": row[\"unadjusted_cost\"] / num_months,\n",
    "        \"deaths\": row[\"deaths\"] / num_months\n",
    "    })"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "query = \"\"\"SELECT * FROM \"cspc5071-dsa\".\"public\".\"us_national_disaster\";\"\"\"\n",
    "df_us_disasters = querying_to_redshift(query, cursor)\n",
    "\n",
    "copied_df = df_us_disasters.copy() # creating a deep copy so I don't have to fetch the database all the time\n",
    "\n",
    "# Changing date in format of 'YYYYMMDD' to 'YYYY-MM'\n",
    "df_us_disasters['start_date'] = pd.to_datetime(df_us_disasters['start_date'].astype(str), format='%Y%m%d').dt.strftime('%Y-%m')\n",
    "df_us_disasters['end_date'] = pd.to_datetime(df_us_disasters['end_date'].astype(str), format='%Y%m%d').dt.strftime('%Y-%m')\n",
    "\n",
    "df_us_disasters = pd.concat(df_us_disasters.apply(expand_date_range, axis=1).to_list(), ignore_index=True)\n",
    "\n",
    "df_us_disasters.to_csv(f\"{data_file_path}/date_organized_us_disasters.csv\")  # save data"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Date Preprocessing for Avian Flu in Birds and Humans"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "bird = pd.read_csv(\"../data/data-table.csv\")\n",
    "bird.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "bird['Outbreak Date'] = pd.to_datetime(bird['Outbreak Date'], format='%m-%d-%Y')\n",
    "bird['yyyy_mm'] = bird['Outbreak Date'].dt.strftime('%Y-%m')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "bird.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "human = pd.read_csv(\"../data/h5n1-flu-reported-cases.csv\")\n",
    "human.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "human['Day'] = pd.to_datetime(human['Day'], format = '%Y-%d-%m')\n",
    "human['yyyy_mm'] = human['Day'].dt.strftime('%Y-%m')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "human.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "bird.to_csv(f\"{data_file_path}/date_organized_avian_flu_bird.csv\")\n",
    "human.to_csv(f\"{data_file_path}/date_organized_avian_flu_human.csv\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_us_population.to_csv(f\"{data_file_path}/date_organized_us_population.csv\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Date preprocessing for Price Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "query = \"\"\"SELECT * FROM \"average_egg_price\";\"\"\"\n",
    "df_egg_price = querying_to_redshift(query, cursor)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_egg_price['date'] = pd.to_datetime(df_egg_price['observation_date']).dt.strftime('%Y-%m')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_egg_price = df_egg_price[['date', 'price_per_dozen']].copy()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_egg_price.to_csv(f\"{data_file_path}/date_organized_egg_price_for_merge.csv\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Date preprocessing for covid-19 data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "query = \"\"\"SELECT * FROM \"cspc5071-dsa\".\"public\".\"covid_hospitalization\";\"\"\"\n",
    "df_covid = querying_to_redshift(query, cursor)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_covid_us = df_covid[df_covid['entity'] == 'United States'].copy()\n",
    "df_covid_us['date'] = ((pd.to_datetime(df_covid_us['day'])).dt.to_period('M')).dt.strftime('%Y-%m')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_covid_us = df_covid_us.groupby('date', as_index=False)['daily_hospital_occupancy'].mean().rename(columns={'daily_hospital_occupancy':'avg_daily_hospitalized'})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_covid_us.to_csv(f\"{data_file_path}/date_organized_us_covid.csv\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Data preprocessing for Weather Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "data_WA = pd.read_csv(f\"{data_file_path}/open-meteo-seattle.csv\").iloc[2:, 0:2].rename(columns={'latitude':'day', 'longitude':'temp_WA'})\n",
    "data_IN = pd.read_csv(f\"{data_file_path}/open-meteo-indiana.csv\").iloc[2:, 0:2].rename(columns={'latitude':'day', 'longitude':'temp_IN'})\n",
    "data_MO = pd.read_csv(f\"{data_file_path}/open-meteo-missouri.csv\").iloc[2:, 0:2].rename(columns={'latitude':'day', 'longitude':'temp_MO'})\n",
    "data_WI = pd.read_csv(f\"{data_file_path}/open-meteo-wisconsin.csv\").iloc[2:, 0:2].rename(columns={'latitude':'day', 'longitude':'temp_WI'})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_weather = ft.reduce(lambda left,right: pd.merge(left,right,on=['day'],\n",
    "                                            how='outer'), [data_WA, data_IN, data_MO, data_WI])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_weather['date'] = ((pd.to_datetime(df_weather['day'])).dt.to_period('M')).dt.strftime('%Y-%m')\n",
    "df_weather[['temp_WA', 'temp_IN', 'temp_MO', 'temp_WI']] = df_weather[['temp_WA', 'temp_IN', 'temp_MO', 'temp_WI']].apply(pd.to_numeric)\n",
    "weather_agg = df_weather.groupby('date', as_index=False)[['temp_WA', 'temp_IN', 'temp_MO', 'temp_WI']].mean()\n",
    "\n",
    "weather_agg.to_csv(f\"{data_file_path}/date_organized_weather_agg.csv\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Date Preprocessing for Gas Price Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_gas = pd.read_csv(f\"{data_file_path}/raw_gas_price.csv\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "base",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
